"use client";

import { useEffect, useRef, useState } from "react";
import * as faceapi from "face-api.js";
import { Button } from "@/components/ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "@/components/ui/card";
import { Badge } from "@/components/ui/badge";
import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogHeader,
  DialogTitle,
} from "@/components/ui/dialog";
import {
  CheckCircle,
  XCircle,
  AlertCircle,
  Camera,
  Shield,
  Users,
  Loader2,
  Eye,
  Zap,
  Settings,
} from "lucide-react";

interface Descriptors {
  name: string;
  descriptor: Float32Array;
}

interface PopupState {
  open: boolean;
  msg: string;
  type: "success" | "error" | "warning";
}

const registeredImages = [
  { name: "Rodrigo Moreira Santos", src: "/registered/rodrigo.jpg" },
  { name: "Rodrigo Moreira Santos", src: "/registered/rodrigo1.jpg" },
  { name: "Rodrigo Moreira Santos", src: "/registered/rodrigo3.jpg" },
];

const FaceRecognition = () => {
  console.log("ğŸš€ FaceRecognition component mounted");
  console.log("ğŸ“‹ Imagens configuradas:", registeredImages);
  console.log("ğŸ“Š NÃºmero de imagens:", registeredImages.length);

  const videoRef = useRef<HTMLVideoElement | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [descriptors, setDescriptors] = useState<Descriptors[]>([]);
  const [popup, setPopup] = useState<PopupState>({
    open: false,
    msg: "",
    type: "warning",
  });
  const [recognitionThreshold] = useState(0.35); // ALTÃSSIMA PRECISÃƒO - aceita apenas distÃ¢ncias menores que 0.35 (similaridade > 65%)
  const [debugInfo, setDebugInfo] = useState<string>("");
  const [lastRecognitionAttempt, setLastRecognitionAttempt] =
    useState<string>("");
  const [debugSteps, setDebugSteps] = useState<string[]>([]);

  // Monitora mudanÃ§as no popup para debug
  useEffect(() => {
    console.log("Estado do popup mudou:", popup);
  }, [popup]);

  // Monitora mudanÃ§as nos descritores para debug
  useEffect(() => {
    console.log("ğŸ”„ Descriptors state changed:", descriptors.length);
    console.log("ğŸ“Š Descriptors details:", descriptors);

    if (descriptors.length > 0) {
      console.log("âœ… Descritores carregados com sucesso!");
      console.log("ğŸ“‹ Detalhes dos descritores:");
      descriptors.forEach((desc, index) => {
        console.log(
          `   ${index + 1}. ${desc.name} - ${desc.descriptor.length} valores`
        );
      });
    }
  }, [descriptors]);

  // Log quando modelsLoaded muda
  useEffect(() => {
    console.log("ğŸ”„ Models loaded state changed:", modelsLoaded);
  }, [modelsLoaded]);

  // FunÃ§Ã£o para forÃ§ar carregamento manual dos modelos
  const forceLoadModels = async () => {
    console.log("ğŸ”§ ForÃ§ando carregamento manual dos modelos...");
    try {
      console.log("ğŸ”„ Carregando tinyFaceDetector...");
      await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
      console.log("âœ… tinyFaceDetector carregado");

      console.log("ğŸ”„ Carregando faceLandmark68Net...");
      await faceapi.nets.faceLandmark68Net.loadFromUri("/models");
      console.log("âœ… faceLandmark68Net carregado");

      console.log("ğŸ”„ Carregando faceRecognitionNet...");
      await faceapi.nets.faceRecognitionNet.loadFromUri("/models");
      console.log("âœ… faceRecognitionNet carregado");

      setModelsLoaded(true);
      console.log("ğŸ‰ MODELOS CARREGADOS MANUALMENTE COM SUCESSO!");
    } catch (error) {
      console.error("âŒ Erro ao carregar modelos manualmente:", error);
      setPopup({
        open: true,
        msg: `Erro ao carregar modelos: ${error}`,
        type: "error",
      });
    }
  };

  // FunÃ§Ã£o para forÃ§ar carregamento manual das imagens
  const forceLoadImages = async () => {
    console.log("ğŸ”§ ForÃ§ando carregamento manual das imagens...");
    console.log("ğŸ¤– Models loaded:", modelsLoaded);
    console.log("ğŸ“‹ Imagens configuradas:", registeredImages);

    if (!modelsLoaded) {
      console.log("âŒ Models not loaded, cannot load images");
      return;
    }

    const descs: Descriptors[] = [];
    console.log("ğŸ”„ Carregando imagens registradas manualmente...");
    console.log("ğŸ“Š NÃºmero de imagens:", registeredImages.length);

    for (let i = 0; i < registeredImages.length; i++) {
      const reg = registeredImages[i];
      try {
        console.log(
          `\nğŸ–¼ï¸ [${i + 1}/${registeredImages.length}] Tentando carregar: ${
            reg.src
          }`
        );

        // Testa se a imagem existe primeiro
        console.log(`ğŸ” Verificando se ${reg.src} existe...`);
        const response = await fetch(reg.src);
        console.log(
          `ğŸ“¡ Response status: ${response.status} ${response.statusText}`
        );

        if (!response.ok) {
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }
        console.log(
          `âœ… [${i + 1}/${
            registeredImages.length
          }] Imagem existe no servidor: ${reg.src}`
        );

        console.log(`ğŸ–¼ï¸ Carregando imagem ${reg.src}...`);
        const img = await faceapi.fetchImage(reg.src);
        console.log(
          `âœ… [${i + 1}/${
            registeredImages.length
          }] Imagem carregada do servidor: ${reg.src}`
        );
        console.log(
          `ğŸ“ [${i + 1}/${registeredImages.length}] DimensÃµes da imagem: ${
            img.width
          }x${img.height}`
        );

        // Tenta detectar face com diferentes configuraÃ§Ãµes
        let detection = null;

        // Primeira tentativa: configuraÃ§Ã£o padrÃ£o
        console.log(`ğŸ” Tentando detectar face em ${reg.src}...`);
        try {
          detection = await faceapi
            .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceDescriptor();
          console.log(
            `âœ… [${i + 1}/${
              registeredImages.length
            }] DetecÃ§Ã£o bem-sucedida com configuraÃ§Ã£o padrÃ£o`
          );
        } catch (detectionError) {
          console.warn(
            `âš ï¸ [${i + 1}/${
              registeredImages.length
            }] Falha na detecÃ§Ã£o padrÃ£o:`,
            detectionError
          );
          console.warn(
            `âš ï¸ [${i + 1}/${
              registeredImages.length
            }] Tentando configuraÃ§Ã£o alternativa...`
          );

          // Segunda tentativa: configuraÃ§Ã£o mais permissiva
          try {
            detection = await faceapi
              .detectSingleFace(
                img,
                new faceapi.TinyFaceDetectorOptions({
                  inputSize: 512,
                  scoreThreshold: 0.3,
                })
              )
              .withFaceLandmarks()
              .withFaceDescriptor();
            console.log(
              `âœ… [${i + 1}/${
                registeredImages.length
              }] DetecÃ§Ã£o bem-sucedida com configuraÃ§Ã£o alternativa`
            );
          } catch (altError) {
            console.error(
              `âŒ [${i + 1}/${
                registeredImages.length
              }] Falha em ambas as tentativas de detecÃ§Ã£o:`,
              altError
            );
            throw altError;
          }
        }

        // Terceira tentativa: configuraÃ§Ã£o especÃ­fica para Mac (muito permissiva)
        if (!detection) {
          console.warn(
            `âš ï¸ [${i + 1}/${
              registeredImages.length
            }] Tentando configuraÃ§Ã£o especÃ­fica para Mac...`
          );
          try {
            detection = await faceapi
              .detectSingleFace(
                img,
                new faceapi.TinyFaceDetectorOptions({
                  inputSize: 1024,
                  scoreThreshold: 0.01, // Muito permissivo para Mac
                })
              )
              .withFaceLandmarks()
              .withFaceDescriptor();
            console.log(
              `âœ… [${i + 1}/${
                registeredImages.length
              }] DetecÃ§Ã£o bem-sucedida com configuraÃ§Ã£o especÃ­fica para Mac`
            );
          } catch (macError) {
            console.error(
              `âŒ [${i + 1}/${
                registeredImages.length
              }] Falha em todas as tentativas de detecÃ§Ã£o:`,
              macError
            );
            throw macError;
          }
        }

        if (detection) {
          descs.push({
            name: reg.name,
            descriptor: detection.descriptor,
          });
          console.log(
            `âœ… [${i + 1}/${
              registeredImages.length
            }] Imagem carregada com sucesso: ${reg.name} (${reg.src})`
          );
          console.log(
            `   ğŸ“Š Descritor criado com ${detection.descriptor.length} valores`
          );
          console.log(
            `   ğŸ¯ ConfianÃ§a da detecÃ§Ã£o: ${detection.detection.score.toFixed(
              4
            )}`
          );
        } else {
          console.warn(
            `âŒ [${i + 1}/${
              registeredImages.length
            }] Nenhum rosto detectado em: ${reg.name} (${reg.src})`
          );
          console.warn(
            `   ğŸ’¡ Verifique se a imagem ${reg.src} contÃ©m um rosto claro e bem iluminado`
          );
        }
      } catch (error) {
        console.error(
          `âŒ [${i + 1}/${registeredImages.length}] Erro ao carregar imagem ${
            reg.name
          } (${reg.src}):`,
          error
        );
        console.error(
          `   ğŸ” Verifique se o arquivo ${reg.src} existe na pasta /public/registered/`
        );
      }
    }

    console.log(`\nğŸ“Š Total de descritores carregados: ${descs.length}`);
    console.log("ğŸ”„ Chamando setDescriptors manualmente...");
    setDescriptors(descs);
    console.log("âœ… setDescriptors chamado manualmente");

    if (descs.length === 0) {
      console.error(
        "âš ï¸ NENHUM DESCRITOR CARREGADO! O reconhecimento nÃ£o funcionarÃ¡."
      );
      setPopup({
        open: true,
        msg: "ERRO: Nenhuma imagem registrada foi carregada. Verifique se as imagens estÃ£o na pasta /public/registered/ e contÃªm rostos claros.",
        type: "error",
      });
    } else {
      console.log("âœ… Descritores carregados com sucesso manualmente!");
      console.log("ğŸ“‹ Descritores disponÃ­veis:");
      descs.forEach((desc, index) => {
        console.log(
          `   ${index + 1}. ${desc.name} - ${desc.descriptor.length} valores`
        );
      });
    }
  };
  const [isProcessing, setIsProcessing] = useState(false);
  const [cameraActive, setCameraActive] = useState(false);
  const [cameraError, setCameraError] = useState<string>("");
  const [personDetected, setPersonDetected] = useState(false);
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);

  // Carrega os modelos do face-api.js
  useEffect(() => {
    const loadModels = async () => {
      try {
        console.log("ğŸ”§ Iniciando carregamento dos modelos...");
        console.log("ğŸ“ Verificando se os modelos existem...");

        // Testa se os arquivos dos modelos existem
        const modelFiles = [
          "/models/tiny_face_detector_model-weights_manifest.json",
          "/models/face_landmark_68_model-weights_manifest.json",
          "/models/face_recognition_model-weights_manifest.json",
        ];

        for (const file of modelFiles) {
          try {
            const response = await fetch(file);
            console.log(
              `ğŸ“¡ ${file}: ${response.status} ${response.statusText}`
            );
            if (!response.ok) {
              throw new Error(
                `HTTP ${response.status}: ${response.statusText}`
              );
            }
          } catch (fileError) {
            console.error(`âŒ Erro ao verificar ${file}:`, fileError);
            throw fileError;
          }
        }

        console.log("âœ… Todos os arquivos de modelo existem, carregando...");

        console.log("ğŸ”„ Carregando tinyFaceDetector...");
        await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
        console.log("âœ… tinyFaceDetector carregado");

        console.log("ğŸ”„ Carregando faceLandmark68Net...");
        await faceapi.nets.faceLandmark68Net.loadFromUri("/models");
        console.log("âœ… faceLandmark68Net carregado");

        console.log("ğŸ”„ Carregando faceRecognitionNet...");
        await faceapi.nets.faceRecognitionNet.loadFromUri("/models");
        console.log("âœ… faceRecognitionNet carregado");

        setModelsLoaded(true);
        console.log("ğŸ‰ TODOS OS MODELOS CARREGADOS COM SUCESSO!");
      } catch (error) {
        console.error("âŒ Erro ao carregar modelos:", error);
        setPopup({
          open: true,
          msg: `Erro ao carregar modelos de IA: ${error}. Verifique se os arquivos estÃ£o na pasta /public/models`,
          type: "error",
        });
      }
    };
    loadModels();
  }, []);

  // FunÃ§Ã£o para iniciar a cÃ¢mera
  const startCamera = async () => {
    try {
      console.log("Solicitando acesso Ã  cÃ¢mera...");
      setCameraError("");

      // Para qualquer stream existente
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
        streamRef.current = null;
      }

      // ConfiguraÃ§Ãµes otimizadas para webcams do Mac - MÃ¡xima qualidade
      const constraints = {
        video: {
          width: { ideal: 1920, min: 1280 }, // ResoluÃ§Ã£o Full HD ou maior
          height: { ideal: 1080, min: 720 },
          facingMode: "user",
          // ConfiguraÃ§Ãµes especÃ­ficas para Mac
          frameRate: { ideal: 30, min: 15 },
          // ForÃ§a o uso da cÃ¢mera frontal
          deviceId: undefined, // SerÃ¡ selecionada automaticamente
          // ConfiguraÃ§Ãµes especÃ­ficas para webcams do Mac
          aspectRatio: { ideal: 16 / 9 },
          // Qualidade mÃ¡xima para reconhecimento facial
          resizeMode: "crop-and-scale",
        },
        audio: false,
      };

      console.log("ğŸ”§ ConfiguraÃ§Ãµes da cÃ¢mera para Mac:", constraints);
      console.log("ğŸ’¡ DiferenÃ§as entre webcams:");
      console.log("   - Webcam pessoal: Geralmente melhor qualidade");
      console.log("   - Webcam do Mac: Pode ter resoluÃ§Ã£o menor");
      console.log("   - ConfiguraÃ§Ãµes otimizadas para Mac aplicadas");

      const mediaStream = await navigator.mediaDevices.getUserMedia(
        constraints
      );

      console.log(
        "Stream obtido:",
        mediaStream.getVideoTracks().length,
        "tracks de vÃ­deo"
      );

      // Log das configuraÃ§Ãµes reais da cÃ¢mera
      const videoTrack = mediaStream.getVideoTracks()[0];
      const settings = videoTrack.getSettings();
      console.log("ğŸ“¹ ConfiguraÃ§Ãµes reais da cÃ¢mera:", settings);
      console.log("ğŸ“ ResoluÃ§Ã£o:", settings.width, "x", settings.height);
      console.log("ğŸ¬ Frame rate:", settings.frameRate);
      console.log("ğŸ“· Device ID:", settings.deviceId);
      console.log(
        "ğŸ” Tipo de cÃ¢mera:",
        settings.deviceId?.includes("Mac") ? "Webcam do Mac" : "Webcam externa"
      );

      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;
        streamRef.current = mediaStream;
        setCameraActive(true);
        console.log("CÃ¢mera ativada com sucesso!");

        // Aguarda o vÃ­deo estar pronto
        videoRef.current.onloadedmetadata = () => {
          console.log("VÃ­deo carregado e pronto");
          console.log(
            "ğŸ“¹ DimensÃµes do vÃ­deo:",
            videoRef.current?.videoWidth,
            "x",
            videoRef.current?.videoHeight
          );
          videoRef.current?.play().catch(console.error);

          // O reconhecimento serÃ¡ iniciado automaticamente quando os descritores estiverem prontos
          console.log("VÃ­deo pronto, aguardando descritores...");
        };
      }
    } catch (error) {
      console.error("Erro ao acessar webcam:", error);
      setCameraError(
        error instanceof Error ? error.message : "Erro desconhecido"
      );
      setCameraActive(false);
    }
  };

  // Inicia a cÃ¢mera quando os modelos estiverem carregados
  useEffect(() => {
    if (modelsLoaded && !cameraActive) {
      console.log("Modelos carregados, iniciando cÃ¢mera...");
      startCamera();
    }
  }, [modelsLoaded, cameraActive]);

  // Inicia o reconhecimento quando os descritores estiverem carregados
  useEffect(() => {
    if (
      modelsLoaded &&
      descriptors.length > 0 &&
      cameraActive &&
      !detectionIntervalRef.current
    ) {
      console.log("ğŸ¯ Descritores carregados, iniciando reconhecimento...");
      console.log("ğŸ“Š Descritores disponÃ­veis:", descriptors.length);
      startFaceRecognition();
    }
  }, [modelsLoaded, descriptors.length, cameraActive]);

  // Cleanup function
  useEffect(() => {
    return () => {
      console.log("Cleanup: parando stream e intervalos");
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => {
          console.log("Parando track:", track.kind);
          track.stop();
        });
        streamRef.current = null;
      }
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
        detectionIntervalRef.current = null;
      }
    };
  }, []);

  // Carrega descritores das imagens registradas
  useEffect(() => {
    console.log("ğŸ”„ useEffect loadImages triggered");
    console.log("ğŸ¤– Models loaded:", modelsLoaded);

    if (!modelsLoaded) {
      console.log("âŒ Models not loaded yet, skipping image loading");
      return;
    }

    const loadImages = async () => {
      try {
        const descs: Descriptors[] = [];
        console.log("ğŸ”„ Carregando imagens registradas...");
        console.log("ğŸ“‹ Imagens configuradas:", registeredImages);
        console.log("ğŸ“Š NÃºmero de imagens:", registeredImages.length);

        for (let i = 0; i < registeredImages.length; i++) {
          const reg = registeredImages[i];
          try {
            console.log(
              `\nğŸ–¼ï¸ [${i + 1}/${registeredImages.length}] Tentando carregar: ${
                reg.src
              }`
            );

            // Testa se a imagem existe primeiro
            console.log(`ğŸ” Verificando se ${reg.src} existe...`);
            const response = await fetch(reg.src);
            console.log(
              `ğŸ“¡ Response status: ${response.status} ${response.statusText}`
            );

            if (!response.ok) {
              throw new Error(
                `HTTP ${response.status}: ${response.statusText}`
              );
            }
            console.log(
              `âœ… [${i + 1}/${
                registeredImages.length
              }] Imagem existe no servidor: ${reg.src}`
            );

            console.log(`ğŸ–¼ï¸ Carregando imagem ${reg.src}...`);
            const img = await faceapi.fetchImage(reg.src);
            console.log(
              `âœ… [${i + 1}/${
                registeredImages.length
              }] Imagem carregada do servidor: ${reg.src}`
            );
            console.log(
              `ğŸ“ [${i + 1}/${registeredImages.length}] DimensÃµes da imagem: ${
                img.width
              }x${img.height}`
            );

            // Tenta detectar face com diferentes configuraÃ§Ãµes
            let detection = null;

            // Primeira tentativa: configuraÃ§Ã£o padrÃ£o
            console.log(`ğŸ” Tentando detectar face em ${reg.src}...`);
            try {
              detection = await faceapi
                .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions())
                .withFaceLandmarks()
                .withFaceDescriptor();
              console.log(
                `âœ… [${i + 1}/${
                  registeredImages.length
                }] DetecÃ§Ã£o bem-sucedida com configuraÃ§Ã£o padrÃ£o`
              );
            } catch (detectionError) {
              console.warn(
                `âš ï¸ [${i + 1}/${
                  registeredImages.length
                }] Falha na detecÃ§Ã£o padrÃ£o:`,
                detectionError
              );
              console.warn(
                `âš ï¸ [${i + 1}/${
                  registeredImages.length
                }] Tentando configuraÃ§Ã£o alternativa...`
              );

              // Segunda tentativa: configuraÃ§Ã£o mais permissiva
              try {
                detection = await faceapi
                  .detectSingleFace(
                    img,
                    new faceapi.TinyFaceDetectorOptions({
                      inputSize: 512,
                      scoreThreshold: 0.3,
                    })
                  )
                  .withFaceLandmarks()
                  .withFaceDescriptor();
                console.log(
                  `âœ… [${i + 1}/${
                    registeredImages.length
                  }] DetecÃ§Ã£o bem-sucedida com configuraÃ§Ã£o alternativa`
                );
              } catch (altError) {
                console.error(
                  `âŒ [${i + 1}/${
                    registeredImages.length
                  }] Falha em ambas as tentativas de detecÃ§Ã£o:`,
                  altError
                );
                throw altError;
              }
            }

            // Terceira tentativa: configuraÃ§Ã£o especÃ­fica para Mac (muito permissiva)
            if (!detection) {
              console.warn(
                `âš ï¸ [${i + 1}/${
                  registeredImages.length
                }] Tentando configuraÃ§Ã£o especÃ­fica para Mac...`
              );
              try {
                detection = await faceapi
                  .detectSingleFace(
                    img,
                    new faceapi.TinyFaceDetectorOptions({
                      inputSize: 1024,
                      scoreThreshold: 0.01, // Muito permissivo para Mac
                    })
                  )
                  .withFaceLandmarks()
                  .withFaceDescriptor();
                console.log(
                  `âœ… [${i + 1}/${
                    registeredImages.length
                  }] DetecÃ§Ã£o bem-sucedida com configuraÃ§Ã£o especÃ­fica para Mac`
                );
              } catch (macError) {
                console.error(
                  `âŒ [${i + 1}/${
                    registeredImages.length
                  }] Falha em todas as tentativas de detecÃ§Ã£o:`,
                  macError
                );
                throw macError;
              }
            }

            if (detection) {
              descs.push({
                name: reg.name,
                descriptor: detection.descriptor,
              });
              console.log(
                `âœ… [${i + 1}/${
                  registeredImages.length
                }] Imagem carregada com sucesso: ${reg.name} (${reg.src})`
              );
              console.log(
                `   ğŸ“Š Descritor criado com ${detection.descriptor.length} valores`
              );
              console.log(
                `   ğŸ¯ ConfianÃ§a da detecÃ§Ã£o: ${detection.detection.score.toFixed(
                  4
                )}`
              );
            } else {
              console.warn(
                `âŒ [${i + 1}/${
                  registeredImages.length
                }] Nenhum rosto detectado em: ${reg.name} (${reg.src})`
              );
              console.warn(
                `   ğŸ’¡ Verifique se a imagem ${reg.src} contÃ©m um rosto claro e bem iluminado`
              );
            }
          } catch (error) {
            console.error(
              `âŒ [${i + 1}/${
                registeredImages.length
              }] Erro ao carregar imagem ${reg.name} (${reg.src}):`,
              error
            );
            console.error(
              `   ğŸ” Verifique se o arquivo ${reg.src} existe na pasta /public/registered/`
            );
          }
        }

        console.log(`\nğŸ“Š Total de descritores carregados: ${descs.length}`);
        console.log("ğŸ”„ Chamando setDescriptors...");
        setDescriptors(descs);
        console.log("âœ… setDescriptors chamado");

        if (descs.length === 0) {
          console.error(
            "âš ï¸ NENHUM DESCRITOR CARREGADO! O reconhecimento nÃ£o funcionarÃ¡."
          );
          setPopup({
            open: true,
            msg: "ERRO: Nenhuma imagem registrada foi carregada. Verifique se as imagens estÃ£o na pasta /public/registered/ e contÃªm rostos claros.",
            type: "error",
          });
        } else {
          console.log("âœ… Descritores carregados com sucesso!");
          console.log("ğŸ“‹ Descritores disponÃ­veis:");
          descs.forEach((desc, index) => {
            console.log(
              `   ${index + 1}. ${desc.name} - ${
                desc.descriptor.length
              } valores`
            );
          });
        }
      } catch (error) {
        console.error("Erro ao carregar imagens:", error);
      }
    };

    loadImages();
  }, [modelsLoaded]);

  // FunÃ§Ã£o para iniciar o reconhecimento facial
  const startFaceRecognition = () => {
    console.log("Iniciando sistema de reconhecimento facial...");

    if (detectionIntervalRef.current) {
      console.log("Limpando intervalo anterior...");
      clearInterval(detectionIntervalRef.current);
    }

    console.log("Criando novo intervalo de detecÃ§Ã£o...");
    detectionIntervalRef.current = setInterval(async () => {
      console.log("Intervalo executando...");
      console.log("Video ref:", !!videoRef.current);
      console.log("Canvas ref:", !!canvasRef.current);
      console.log("Is processing:", isProcessing);

      if (!videoRef.current || !canvasRef.current || isProcessing) {
        console.log("CondiÃ§Ãµes nÃ£o atendidas para execuÃ§Ã£o do intervalo");
        return;
      }

      try {
        console.log("Iniciando processamento...");
        setIsProcessing(true);
        await performFaceRecognition();
      } catch (error) {
        console.error("Erro no reconhecimento:", error);
      } finally {
        console.log("Finalizando processamento...");
        setIsProcessing(false);
      }
    }, 1000); // Verifica a cada segundo

    console.log("Intervalo de detecÃ§Ã£o criado com sucesso");
  };

  // FunÃ§Ã£o principal de reconhecimento facial
  const performFaceRecognition = async () => {
    console.log("ğŸ” Iniciando reconhecimento facial...");
    setDebugSteps(["ğŸ” Iniciando reconhecimento facial..."]);

    console.log("ğŸ“¹ Video ref:", !!videoRef.current);
    console.log("ğŸ¨ Canvas ref:", !!canvasRef.current);
    console.log("ğŸ¤– Models loaded:", modelsLoaded);
    console.log("ğŸ‘¥ Descriptors count:", descriptors.length);
    console.log("ğŸ¯ Threshold atual:", recognitionThreshold);
    console.log("ğŸ“Š Descriptors details:", descriptors);

    // VerificaÃ§Ãµes de seguranÃ§a mais robustas
    if (!videoRef.current) {
      console.log("âŒ Video ref Ã© null");
      setDebugInfo("âŒ Video ref Ã© null");
      setLastRecognitionAttempt("âŒ Video ref Ã© null");
      setDebugSteps((prev) => [...prev, "âŒ Video ref Ã© null"]);
      return;
    }

    if (!canvasRef.current) {
      console.log("âŒ Canvas ref Ã© null");
      setDebugInfo("âŒ Canvas ref Ã© null");
      setLastRecognitionAttempt("âŒ Canvas ref Ã© null");
      setDebugSteps((prev) => [...prev, "âŒ Canvas ref Ã© null"]);
      return;
    }

    if (!modelsLoaded) {
      console.log("âŒ Models nÃ£o carregados");
      setDebugInfo("âŒ Models nÃ£o carregados");
      setLastRecognitionAttempt("âŒ Models nÃ£o carregados");
      setDebugSteps((prev) => [...prev, "âŒ Models nÃ£o carregados"]);
      return;
    }

    // VerificaÃ§Ã£o adicional para vÃ­deo estar pronto
    if (
      videoRef.current.videoWidth === 0 ||
      videoRef.current.videoHeight === 0
    ) {
      console.log("âŒ VÃ­deo nÃ£o estÃ¡ pronto (dimensÃµes zero)");
      setDebugInfo("âŒ VÃ­deo nÃ£o estÃ¡ pronto");
      setLastRecognitionAttempt("âŒ VÃ­deo nÃ£o estÃ¡ pronto");
      setDebugSteps((prev) => [...prev, "âŒ VÃ­deo nÃ£o estÃ¡ pronto"]);
      return;
    }

    if (descriptors.length === 0) {
      console.log("âŒ Nenhum descritor carregado - reconhecimento impossÃ­vel");
      setDebugInfo("âŒ Nenhum descritor carregado");
      setLastRecognitionAttempt("âŒ Nenhum descritor carregado");
      setDebugSteps((prev) => [...prev, "âŒ Nenhum descritor carregado"]);
      setPopup({
        open: true,
        msg: "ERRO: Nenhuma pessoa registrada. Adicione imagens na pasta /public/registered/",
        type: "error",
      });
      return;
    }

    // VerificaÃ§Ã£o adicional para stream estar ativo
    if (!streamRef.current || !streamRef.current.active) {
      console.log("âŒ Stream nÃ£o estÃ¡ ativo");
      setDebugInfo("âŒ Stream nÃ£o estÃ¡ ativo");
      setLastRecognitionAttempt("âŒ Stream nÃ£o estÃ¡ ativo");
      setDebugSteps((prev) => [...prev, "âŒ Stream nÃ£o estÃ¡ ativo"]);
      return;
    }

    // Fecha popup anterior antes de fazer nova verificaÃ§Ã£o
    if (popup.open) {
      console.log("ğŸ”„ Fechando popup anterior para nova verificaÃ§Ã£o...");
      closePopup();
    }

    try {
      // Detecta faces no vÃ­deo com configuraÃ§Ãµes especÃ­ficas para Mac
      console.log("ğŸ” Detectando faces no vÃ­deo...");
      setDebugInfo("ğŸ” Detectando faces...");
      setLastRecognitionAttempt("ğŸ” Detectando faces...");
      setDebugSteps((prev) => [...prev, "ğŸ” Detectando faces no vÃ­deo..."]);

      // ConfiguraÃ§Ãµes otimizadas para webcams do Mac - EXTREMAMENTE permissivas para teste
      const detectorOptions = new faceapi.TinyFaceDetectorOptions({
        inputSize: 1024, // Input size maior para mÃ¡xima precisÃ£o
        scoreThreshold: 0.01, // Threshold EXTREMAMENTE baixo para detectar rostos em qualquer condiÃ§Ã£o
      });

      console.log("ğŸ”§ ConfiguraÃ§Ãµes do detector (EXTREMAMENTE PERMISSIVAS):", {
        inputSize: detectorOptions.inputSize,
        scoreThreshold: detectorOptions.scoreThreshold,
      });

      // Log das configuraÃ§Ãµes da cÃ¢mera para debug
      if (videoRef.current) {
        console.log("ğŸ“¹ InformaÃ§Ãµes da cÃ¢mera:");
        console.log("   - Video width:", videoRef.current.videoWidth);
        console.log("   - Video height:", videoRef.current.videoHeight);
        console.log(
          "   - Device ID:",
          videoRef.current.srcObject
            ? (videoRef.current.srcObject as MediaStream)
                .getVideoTracks()[0]
                ?.getSettings().deviceId
            : "N/A"
        );

        // DetecÃ§Ã£o especÃ­fica para Mac
        const deviceId = videoRef.current.srcObject
          ? (videoRef.current.srcObject as MediaStream)
              .getVideoTracks()[0]
              ?.getSettings().deviceId
          : "";
        const isMacCamera =
          deviceId &&
          (deviceId.includes("Mac") ||
            deviceId.includes("FaceTime") ||
            deviceId.includes("Built-in"));
        console.log("ğŸ Ã‰ cÃ¢mera do Mac:", isMacCamera);

        if (isMacCamera) {
          console.log("ğŸ’¡ OtimizaÃ§Ãµes especÃ­ficas para Mac aplicadas:");
          console.log("   - Detector mais sensÃ­vel");
          console.log("   - Threshold mais permissivo");
          console.log("   - ConfiguraÃ§Ãµes adaptadas para qualidade do Mac");
        }
      }

      const detections = await faceapi
        .detectAllFaces(videoRef.current, detectorOptions)
        .withFaceLandmarks()
        .withFaceDescriptors();

      console.log(`ğŸ‘¤ Faces detectadas: ${detections.length}`);
      setDebugInfo(`ğŸ‘¤ Faces detectadas: ${detections.length}`);
      setLastRecognitionAttempt(`ğŸ‘¤ Faces detectadas: ${detections.length}`);
      setDebugSteps((prev) => [
        ...prev,
        `ğŸ‘¤ Faces detectadas: ${detections.length}`,
      ]);

      if (detections.length === 0) {
        console.log("âŒ Nenhuma face detectada na webcam");
        console.log("ğŸ’¡ PossÃ­veis causas:");
        console.log("   - IluminaÃ§Ã£o insuficiente");
        console.log("   - Posicionamento inadequado");
        console.log("   - Qualidade da webcam do Mac");
        console.log("   - ConfiguraÃ§Ãµes de detector muito restritivas");
        setPersonDetected(false);
        setDebugInfo("âŒ Nenhuma face detectada");
        setLastRecognitionAttempt("âŒ Nenhuma face detectada");
        setDebugSteps((prev) => [...prev, "âŒ Nenhuma face detectada"]);
        return;
      }

      // VERIFICAÃ‡ÃƒO CRÃTICA PARA ESTÃDIO: MÃºltiplas faces
      if (detections.length > 1) {
        console.log("ğŸš« MÃšLTIPLAS FACES DETECTADAS - ACESSO NEGADO");
        console.log("ğŸ’¡ Para estÃ¡dio: Apenas uma pessoa por vez");
        console.log(`ğŸ“Š Faces detectadas: ${detections.length}`);

        // Log das confianÃ§as de cada face
        detections.forEach((detection, index) => {
          console.log(
            `   Face ${
              index + 1
            }: confianÃ§a ${detection.detection.score.toFixed(3)}`
          );
        });

        // VERIFICAÃ‡ÃƒO ADICIONAL: Se a segunda face tem confianÃ§a muito baixa, pode ser falso positivo
        const mainFace = detections[0];
        const secondaryFace = detections[1];

        console.log(
          `ğŸ¯ Face principal: ${mainFace.detection.score.toFixed(3)}`
        );
        console.log(
          `ğŸ¯ Face secundÃ¡ria: ${secondaryFace.detection.score.toFixed(3)}`
        );

        // Se a face secundÃ¡ria tem confianÃ§a muito baixa (< 0.3), pode ser falso positivo
        if (secondaryFace.detection.score < 0.3) {
          console.log(
            "âœ… Face secundÃ¡ria com confianÃ§a baixa - provÃ¡vel falso positivo"
          );
          console.log("ğŸ’¡ Continuando com apenas a face principal");

          // Continua com apenas a primeira face (mais confiÃ¡vel)
          console.log("âœ… Usando apenas face principal para reconhecimento");

          // Continua o processamento com apenas uma face
          setPersonDetected(true);
          setDebugInfo("âœ… Face principal detectada, comparando...");
          setLastRecognitionAttempt(
            "âœ… Face principal detectada, comparando..."
          );
          setDebugSteps((prev) => [
            ...prev,
            "âœ… Face principal detectada, comparando com descritores...",
          ]);

          // Continua com o reconhecimento usando apenas a face principal
          // (o cÃ³digo continua normalmente apÃ³s este bloco)
        } else {
          // Se a segunda face tem confianÃ§a alta, realmente hÃ¡ mÃºltiplas pessoas
          console.log("ğŸš« MÃºltiplas pessoas confirmadas - Acesso negado");

          setPersonDetected(false);
          setDebugInfo(
            `ğŸš« MÃºltiplas faces (${detections.length}) - Acesso negado`
          );
          setLastRecognitionAttempt(
            `ğŸš« MÃºltiplas faces (${detections.length}) - Acesso negado`
          );
          setDebugSteps((prev) => [
            ...prev,
            `ğŸš« MÃºltiplas faces (${detections.length}) - Acesso negado`,
          ]);

          setPopup({
            open: true,
            msg: `Acesso NEGADO! MÃºltiplas pessoas detectadas (${detections.length}). Para estÃ¡dio: apenas uma pessoa por vez.`,
            type: "error",
          });
          return;
        }
      }

      // VERIFICAÃ‡ÃƒO ADICIONAL: Detectar interferÃªncia mesmo com uma face
      const detection = detections[0];
      console.log(
        `ğŸ¯ ConfianÃ§a da detecÃ§Ã£o: ${detection.detection.score.toFixed(3)}`
      );

      // Se a confianÃ§a for muito baixa, pode indicar detecÃ§Ã£o parcial ou interferÃªncia
      if (detection.detection.score < 0.3) {
        console.log(
          "âš ï¸ ConfianÃ§a muito baixa - pode haver interferÃªncia de outras pessoas"
        );
        console.log("ğŸ’¡ Para estÃ¡dio: Posicione-se melhor na frente da cÃ¢mera");

        setPersonDetected(false);
        setDebugInfo("âš ï¸ ConfianÃ§a muito baixa - possÃ­vel interferÃªncia");
        setLastRecognitionAttempt(
          "âš ï¸ ConfianÃ§a muito baixa - possÃ­vel interferÃªncia"
        );
        setDebugSteps((prev) => [
          ...prev,
          "âš ï¸ ConfianÃ§a muito baixa - possÃ­vel interferÃªncia",
        ]);

        setPopup({
          open: true,
          msg: "Acesso NEGADO! DetecÃ§Ã£o com confianÃ§a muito baixa. Posicione-se melhor na frente da cÃ¢mera, sem outras pessoas prÃ³ximas.",
          type: "error",
        });
        return;
      }

      setPersonDetected(true);
      console.log("âœ… Pessoa detectada, comparando com descritores...");
      setDebugInfo("âœ… Pessoa detectada, comparando...");
      setLastRecognitionAttempt("âœ… Pessoa detectada, comparando...");
      setDebugSteps((prev) => [
        ...prev,
        "âœ… Pessoa detectada, comparando com descritores...",
      ]);

      // Desenha os retÃ¢ngulos de detecÃ§Ã£o
      const canvas = canvasRef.current;

      // VerificaÃ§Ã£o de seguranÃ§a para videoRef
      if (!videoRef.current) {
        console.log("âŒ Video ref Ã© null, pulando desenho");
        return;
      }

      const displaySize = {
        width: videoRef.current.videoWidth,
        height: videoRef.current.videoHeight,
      };

      // VerificaÃ§Ã£o adicional para dimensÃµes vÃ¡lidas
      if (displaySize.width === 0 || displaySize.height === 0) {
        console.log("âŒ DimensÃµes do vÃ­deo invÃ¡lidas, pulando desenho");
        return;
      }

      faceapi.matchDimensions(canvas, displaySize);

      const resizedDetections = faceapi.resizeResults(detections, displaySize);
      const ctx = canvas.getContext("2d");
      if (ctx) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Desenha todas as faces detectadas
        faceapi.draw.drawDetections(canvas, resizedDetections);

        // Se hÃ¡ mÃºltiplas faces, adiciona texto de aviso
        if (resizedDetections.length > 1) {
          ctx.fillStyle = "#ff0000";
          ctx.font = "20px Arial";
          ctx.fillText("MÃšLTIPLAS PESSOAS DETECTADAS", 10, 30);
        }
      }

      // Compara com os descritores registrados
      let foundMatch = false;
      let bestMatch = { name: "", distance: Infinity, similarity: 0 };
      const allDistances: string[] = [];
      const highSimilarityMatches: Array<{ name: string; similarity: number }> =
        [];

      console.log(
        `ğŸ” Comparando ${detections.length} face(s) com ${descriptors.length} descritor(es)...`
      );
      setDebugSteps((prev) => [
        ...prev,
        `ğŸ” Comparando ${detections.length} face(s) com ${descriptors.length} descritor(es)...`,
      ]);

      for (const detection of detections) {
        console.log(
          `ğŸ“Š Processando face detectada (confianÃ§a: ${detection.detection.score.toFixed(
            3
          )})`
        );

        console.log(
          `ğŸ” Testando contra ${descriptors.length} descritor(es) registrado(s)...`
        );

        for (let i = 0; i < descriptors.length; i++) {
          const descriptor = descriptors[i];
          const distance = faceapi.euclideanDistance(
            detection.descriptor,
            descriptor.descriptor
          );

          // Calcula similaridade (0-1, onde 1 Ã© idÃªntico)
          const similarity = 1 - Math.min(distance, 1);

          const distanceInfo = `${descriptor.name}: ${distance.toFixed(4)} (${(
            similarity * 100
          ).toFixed(1)}%)`;
          allDistances.push(distanceInfo);

          console.log(
            `ğŸ“ [${i + 1}/${descriptors.length}] ${
              descriptor.name
            }: distÃ¢ncia=${distance.toFixed(
              4
            )}, similaridade=${similarity.toFixed(4)} (${(
              similarity * 100
            ).toFixed(1)}%), threshold=${recognitionThreshold}`
          );

          // Atualiza melhor match para debug
          if (distance < bestMatch.distance) {
            bestMatch = {
              name: descriptor.name,
              distance: distance,
              similarity: similarity,
            };
          }

          // Coleta matches com alta similaridade (possÃ­vel interferÃªncia)
          if (similarity > 0.4) {
            highSimilarityMatches.push({
              name: descriptor.name,
              similarity: similarity,
            });
          }

          // LÃ³gica corrigida: distÃ¢ncia menor = mais similar
          // Para ser reconhecido, a distÃ¢ncia deve ser MENOR que o threshold
          if (distance < recognitionThreshold) {
            console.log(
              `âœ… PESSOA RECONHECIDA: ${
                descriptor.name
              } (distÃ¢ncia: ${distance.toFixed(
                4
              )}, similaridade: ${similarity.toFixed(4)})`
            );
            foundMatch = true;
            setDebugInfo(
              `âœ… RECONHECIDO: ${descriptor.name} (${(similarity * 100).toFixed(
                1
              )}%)`
            );
            setLastRecognitionAttempt(
              `âœ… RECONHECIDO: ${descriptor.name} (${(similarity * 100).toFixed(
                1
              )}%)`
            );
            setDebugSteps((prev) => [
              ...prev,
              `âœ… RECONHECIDO: ${descriptor.name} (${(similarity * 100).toFixed(
                1
              )}%)`,
            ]);
            setPopup({
              open: true,
              msg: `Acesso LIBERADO! Bem-vindo, ${
                descriptor.name
              }! VocÃª possui ingresso vÃ¡lido. (Similaridade: ${(
                similarity * 100
              ).toFixed(1)}%)`,
              type: "success",
            });
            return;
          } else {
            console.log(
              `âŒ [${i + 1}/${descriptors.length}] DistÃ¢ncia muito alta para ${
                descriptor.name
              }: ${distance.toFixed(
                4
              )} >= ${recognitionThreshold} (similaridade: ${(
                similarity * 100
              ).toFixed(1)}%)`
            );

            // Log mais detalhado para pessoas nÃ£o reconhecidas
            if (similarity < 0.3) {
              console.log(
                `ğŸš« PESSOA DESCONHECIDA: Similaridade muito baixa (${(
                  similarity * 100
                ).toFixed(1)}%) - Acesso negado corretamente`
              );
            } else {
              console.log(
                `âš ï¸ SIMILARIDADE INTERMEDIÃRIA: ${(similarity * 100).toFixed(
                  1
                )}% - Pode ser a mesma pessoa com iluminaÃ§Ã£o diferente`
              );
            }
          }
        }
      }

      // VERIFICAÃ‡ÃƒO CRÃTICA: MÃºltiplas pessoas com alta similaridade
      if (highSimilarityMatches.length > 1) {
        console.log("ğŸš« MÃšLTIPLAS PESSOAS COM ALTA SIMILARIDADE DETECTADAS");
        console.log("ğŸ’¡ Isso indica interferÃªncia de outras pessoas na cÃ¢mera");
        console.log("ğŸ“Š Matches com alta similaridade:");
        highSimilarityMatches.forEach((match, index) => {
          console.log(
            `   ${index + 1}. ${match.name}: ${(match.similarity * 100).toFixed(
              1
            )}%`
          );
        });

        setPersonDetected(false);
        setDebugInfo(
          "ğŸš« MÃºltiplas pessoas com alta similaridade - possÃ­vel interferÃªncia"
        );
        setLastRecognitionAttempt(
          "ğŸš« MÃºltiplas pessoas com alta similaridade - possÃ­vel interferÃªncia"
        );
        setDebugSteps((prev) => [
          ...prev,
          "ğŸš« MÃºltiplas pessoas com alta similaridade - possÃ­vel interferÃªncia",
        ]);

        setPopup({
          open: true,
          msg: `Acesso NEGADO! Detectada possÃ­vel interferÃªncia de outras pessoas. Posicione-se sozinho na frente da cÃ¢mera.`,
          type: "error",
        });
        return;
      }

      // Se chegou aqui, nÃ£o reconheceu ninguÃ©m
      if (!foundMatch) {
        console.log("âŒ PESSOA NÃƒO RECONHECIDA");
        console.log("ğŸ“Š Melhor match encontrado:");
        console.log(`   - Nome: ${bestMatch.name}`);
        console.log(`   - DistÃ¢ncia: ${bestMatch.distance.toFixed(4)}`);
        console.log(
          `   - Similaridade: ${(bestMatch.similarity * 100).toFixed(1)}%`
        );
        console.log(
          `   - Threshold: ${recognitionThreshold} (similaridade mÃ­nima: ${(
            (1 - recognitionThreshold) *
            100
          ).toFixed(1)}%)`
        );

        // Mostra todas as distÃ¢ncias para debug
        console.log("ğŸ“Š Todas as distÃ¢ncias:");
        for (const descriptor of descriptors) {
          const distance = faceapi.euclideanDistance(
            detections[0].descriptor,
            descriptor.descriptor
          );
          const similarity = 1 - Math.min(distance, 1);
          console.log(
            `   - ${descriptor.name}: ${distance.toFixed(4)} (${(
              similarity * 100
            ).toFixed(1)}%)`
          );
        }

        // Log especÃ­fico para estÃ¡dio
        if (bestMatch.similarity < 0.6) {
          console.log(
            "ğŸš« ACESSO NEGADO: Similaridade muito baixa para estÃ¡dio"
          );
          console.log("   ğŸ’¡ Para estÃ¡dio: Similaridade mÃ­nima deve ser > 60%");
        } else {
          console.log("âš ï¸ SIMILARIDADE ALTA MAS INSUFICIENTE");
          console.log("   ğŸ’¡ Pode ser a mesma pessoa com condiÃ§Ãµes diferentes");
        }

        setDebugInfo(
          `âŒ NÃƒO RECONHECIDO. Melhor: ${bestMatch.name} (${(
            bestMatch.similarity * 100
          ).toFixed(1)}%)`
        );
        setLastRecognitionAttempt(
          `âŒ NÃƒO RECONHECIDO. Melhor: ${bestMatch.name} (${(
            bestMatch.similarity * 100
          ).toFixed(1)}%)`
        );
        setDebugSteps((prev) => [
          ...prev,
          `âŒ NÃƒO RECONHECIDO. Melhor: ${bestMatch.name} (${(
            bestMatch.similarity * 100
          ).toFixed(1)}%)`,
        ]);
        setPopup({
          open: true,
          msg: `Acesso NEGADO! Pessoa nÃ£o reconhecida. Melhor match: ${
            bestMatch.name
          } (${(bestMatch.similarity * 100).toFixed(
            1
          )}% similaridade). Para estÃ¡dio: similaridade mÃ­nima ${(
            (1 - recognitionThreshold) *
            100
          ).toFixed(1)}%`,
          type: "error",
        });
      }
    } catch (error) {
      console.error("âŒ Erro no reconhecimento facial:", error);
      setDebugInfo(`âŒ Erro: ${error}`);
      setLastRecognitionAttempt(`âŒ Erro: ${error}`);
      setDebugSteps((prev) => [...prev, `âŒ Erro: ${error}`]);
    }
  };

  // FunÃ§Ã£o para fechar popup
  const closePopup = () => {
    console.log("Fechando popup");
    setPopup({ open: false, msg: "", type: "warning" });
  };

  // FunÃ§Ã£o para reiniciar a cÃ¢mera
  const restartCamera = async () => {
    console.log("Reiniciando cÃ¢mera...");

    // Para o stream atual
    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => {
        track.stop();
      });
      streamRef.current = null;
    }

    // Limpa o vÃ­deo
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }

    // Para o intervalo de detecÃ§Ã£o
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }

    // Reseta estados
    setCameraActive(false);
    setCameraError("");
    setPersonDetected(false);

    // Reinicia
    await startCamera();
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900 flex flex-col items-center justify-center p-4">
      {/* Background decorations */}
      <div className="fixed inset-0 overflow-hidden pointer-events-none">
        <div className="absolute -top-40 -right-40 w-80 h-80 bg-blue-500/10 rounded-full blur-3xl"></div>
        <div className="absolute -bottom-40 -left-40 w-80 h-80 bg-purple-500/10 rounded-full blur-3xl"></div>
        <div className="absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 w-96 h-96 bg-gradient-to-r from-blue-600/5 to-purple-600/5 rounded-full blur-3xl"></div>
      </div>

      <div className="relative z-10 w-full max-w-6xl">
        <Card className="bg-white/95 backdrop-blur-sm border-0 shadow-2xl">
          <CardHeader className="text-center border-b border-gray-200/50 pb-8">
            <div className="flex items-center justify-center mb-6">
              <div className="relative">
                <div className="absolute inset-0 bg-gradient-to-r from-blue-500 to-purple-600 rounded-full blur-lg opacity-75"></div>
                <Shield className="relative h-16 w-16 text-white" />
              </div>
            </div>
            <CardTitle className="text-4xl font-bold bg-gradient-to-r from-blue-600 to-purple-600 bg-clip-text text-transparent">
              ğŸŸï¸ Controle de Acesso - EstÃ¡dio
            </CardTitle>
            <CardDescription className="text-xl text-gray-600 mt-2">
              Sistema de Reconhecimento Facial - V2
            </CardDescription>
          </CardHeader>

          <CardContent className="p-8">
            {/* Status dos modelos */}
            <div className="flex flex-wrap gap-4 justify-center mb-8">
              <Badge
                variant={modelsLoaded ? "default" : "secondary"}
                className="flex items-center gap-2 px-6 py-3 text-sm font-medium"
              >
                {modelsLoaded ? (
                  <CheckCircle className="h-4 w-4" />
                ) : (
                  <Loader2 className="h-4 w-4 animate-spin" />
                )}
                {modelsLoaded ? "Modelos carregados" : "Carregando modelos..."}
              </Badge>

              <Badge
                variant={descriptors.length > 0 ? "default" : "destructive"}
                className="flex items-center gap-2 px-6 py-3 text-sm font-medium"
              >
                <Users className="h-4 w-4" />
                {descriptors.length} pessoas registradas
              </Badge>

              <Badge
                variant={cameraActive ? "default" : "secondary"}
                className="flex items-center gap-2 px-6 py-3 text-sm font-medium"
              >
                <Camera className="h-4 w-4" />
                {cameraActive ? "CÃ¢mera ativa" : "CÃ¢mera inativa"}
              </Badge>
            </div>

            {/* Main content grid */}
            <div className="grid lg:grid-cols-2 gap-8 items-start">
              {/* Video container */}
              <div className="space-y-4">
                <div className="text-center">
                  <h3 className="text-lg font-semibold text-gray-800 mb-2 flex items-center justify-center gap-2">
                    <Eye className="h-5 w-5 text-blue-600" />
                    CÃ¢mera de Reconhecimento
                  </h3>
                </div>

                <div className="relative flex justify-center">
                  <div
                    className="relative rounded-2xl overflow-hidden shadow-2xl border-4 border-gray-200 bg-gray-100"
                    style={{ width: "480px", height: "360px" }}
                  >
                    <video
                      ref={videoRef}
                      autoPlay
                      muted
                      playsInline
                      className="w-full h-full object-cover"
                    />
                    <canvas
                      ref={canvasRef}
                      className="absolute top-0 left-0 w-full h-full"
                    />

                    {/* Camera overlay */}
                    <div className="absolute inset-0 bg-gradient-to-t from-black/20 via-transparent to-transparent"></div>

                    {/* Camera status indicator */}
                    <div className="absolute top-4 right-4">
                      <div className="bg-black/70 text-white px-3 py-1 rounded-full text-sm flex items-center gap-2">
                        <div
                          className={`w-2 h-2 rounded-full ${
                            cameraActive ? "bg-green-400" : "bg-red-400"
                          }`}
                        ></div>
                        {cameraActive
                          ? personDetected
                            ? "DETECTED"
                            : "LIVE"
                          : "OFF"}
                      </div>
                    </div>

                    {/* Camera debug info */}
                    {!cameraActive && (
                      <div className="absolute bottom-4 left-4 bg-yellow-500/90 text-white px-3 py-1 rounded text-xs">
                        {cameraError
                          ? `Erro: ${cameraError}`
                          : "Aguardando cÃ¢mera..."}
                      </div>
                    )}
                  </div>
                </div>

                {/* Camera controls */}
                <div className="flex justify-center gap-4">
                  <Button
                    onClick={restartCamera}
                    variant="outline"
                    size="sm"
                    className="flex items-center gap-2"
                  >
                    <Camera className="h-4 w-4" />
                    Reiniciar CÃ¢mera
                  </Button>

                  <Button
                    onClick={forceLoadModels}
                    variant="outline"
                    size="sm"
                    className="flex items-center gap-2"
                  >
                    <Settings className="h-4 w-4" />
                    Carregar Modelos
                  </Button>

                  <Button
                    onClick={forceLoadImages}
                    variant="outline"
                    size="sm"
                    className="flex items-center gap-2"
                  >
                    <Loader2 className="h-4 w-4" />
                    ForÃ§ar Carregamento
                  </Button>
                </div>

                {/* Debug panel */}
                <div className="mt-4 p-4 bg-yellow-50 border border-yellow-200 rounded-lg">
                  <h4 className="text-sm font-semibold text-yellow-800 mb-2">
                    ğŸ”§ Painel de Debug - Sistema Completo
                  </h4>
                  <div className="text-xs space-y-1">
                    <p className="text-yellow-700">
                      â€¢ Modelos carregados: {modelsLoaded ? "âœ…" : "âŒ"}
                    </p>
                    <p className="text-yellow-700">
                      â€¢ Descritores carregados: {descriptors.length}
                    </p>
                    <p className="text-yellow-700">
                      â€¢ Imagens configuradas: {registeredImages.length}
                    </p>
                    <p className="text-yellow-700">
                      â€¢ CÃ¢mera ativa: {cameraActive ? "âœ…" : "âŒ"}
                    </p>

                    {!modelsLoaded && (
                      <div className="mt-2 p-2 bg-red-50 border border-red-200 rounded">
                        <p className="text-red-700 font-medium">
                          âš ï¸ PROBLEMA: Modelos nÃ£o carregados!
                        </p>
                        <p className="text-red-600 text-xs mt-1">
                          Clique em &quot;Carregar Modelos&quot; para tentar
                          carregar manualmente.
                        </p>
                      </div>
                    )}

                    {modelsLoaded && descriptors.length === 0 && (
                      <div className="mt-2 p-2 bg-orange-50 border border-orange-200 rounded">
                        <p className="text-orange-700 font-medium">
                          âš ï¸ PROBLEMA: Modelos OK, mas nenhum descritor
                          carregado!
                        </p>
                        <p className="text-orange-600 text-xs mt-1">
                          Clique em &quot;ForÃ§ar Carregamento&quot; para tentar
                          carregar as imagens.
                        </p>
                      </div>
                    )}

                    {modelsLoaded && descriptors.length > 0 && (
                      <div className="mt-2 p-2 bg-green-50 border border-green-200 rounded">
                        <p className="text-green-700 font-medium">
                          âœ… Sistema pronto para reconhecimento!
                        </p>
                        <p className="text-green-600 text-xs mt-1">
                          Modelos e descritores carregados com sucesso.
                        </p>
                      </div>
                    )}
                  </div>
                </div>

                {/* Status do reconhecimento em tempo real */}
                <div className="text-center pt-4">
                  {personDetected ? (
                    <div className="inline-flex items-center gap-2 px-6 py-3 rounded-full bg-gradient-to-r from-blue-100 to-purple-100 border border-blue-200">
                      <div className="w-2 h-2 bg-blue-500 rounded-full animate-pulse"></div>
                      <span className="text-sm font-medium text-blue-800">
                        ğŸ” Verificando Identidade...
                      </span>
                    </div>
                  ) : (
                    <div className="inline-flex items-center gap-2 px-6 py-3 rounded-full bg-gradient-to-r from-gray-100 to-slate-100 border border-gray-200">
                      <div className="w-2 h-2 bg-gray-400 rounded-full"></div>
                      <span className="text-sm font-medium text-gray-600">
                        Aguardando Pessoa
                      </span>
                    </div>
                  )}
                  <p className="text-xs text-gray-500 mt-2">
                    {personDetected
                      ? "ğŸ” Verificando sua identidade a cada segundo..."
                      : "Posicione-se na frente da cÃ¢mera para verificaÃ§Ã£o automÃ¡tica"}
                  </p>

                  {/* InformaÃ§Ãµes de debug em tempo real */}
                  {personDetected && (
                    <div className="mt-3 p-3 bg-blue-50 rounded-lg border border-blue-200">
                      <p className="text-xs text-blue-700 font-medium">
                        ğŸ“Š Status do Reconhecimento:
                      </p>
                      <p className="text-xs text-blue-600">
                        â€¢ Threshold atual: {recognitionThreshold.toFixed(2)}
                      </p>
                      <p className="text-xs text-blue-600">
                        â€¢ Descritores carregados: {descriptors.length}
                      </p>
                      <p className="text-xs text-blue-600">
                        â€¢ VerificaÃ§Ã£o automÃ¡tica a cada 1 segundo
                      </p>
                      <p className="text-xs text-blue-600 mt-1">
                        ğŸ’¡ <strong>EXTREMAMENTE PERMISSIVO:</strong> Threshold
                        0.95 para forÃ§ar reconhecimento
                      </p>
                      {debugInfo && (
                        <div className="mt-2 p-2 bg-white rounded border">
                          <p className="text-xs text-gray-700 font-medium">
                            Debug:
                          </p>
                          <p className="text-xs text-gray-600">{debugInfo}</p>
                          {lastRecognitionAttempt && (
                            <p className="text-xs text-gray-500 mt-1">
                              Ãšltima tentativa: {lastRecognitionAttempt}
                            </p>
                          )}
                          {debugSteps.length > 0 && (
                            <div className="mt-2">
                              <p className="text-xs text-gray-700 font-medium">
                                Passos:
                              </p>
                              {debugSteps.slice(-5).map((step, index) => (
                                <p
                                  key={index}
                                  className="text-xs text-gray-500"
                                >
                                  {step}
                                </p>
                              ))}
                            </div>
                          )}
                        </div>
                      )}
                    </div>
                  )}
                </div>
              </div>

              {/* Info panel */}
              <div className="space-y-6">
                {/* System Status */}
                <Card className="bg-gradient-to-br from-blue-50 to-purple-50 border-blue-200">
                  <CardHeader>
                    <CardTitle className="text-blue-800 flex items-center gap-2">
                      <Settings className="h-5 w-5" />
                      Status do Sistema
                    </CardTitle>
                  </CardHeader>
                  <CardContent>
                    <div className="space-y-3">
                      <div className="flex items-center justify-between">
                        <span className="text-sm text-gray-600">
                          Modelos de IA:
                        </span>
                        <Badge
                          variant={modelsLoaded ? "default" : "secondary"}
                          className="text-xs"
                        >
                          {modelsLoaded ? "Ativo" : "Carregando..."}
                        </Badge>
                      </div>
                      <div className="flex items-center justify-between">
                        <span className="text-sm text-gray-600">
                          Pessoas registradas:
                        </span>
                        <Badge
                          variant={
                            descriptors.length > 0 ? "default" : "destructive"
                          }
                          className="text-xs"
                        >
                          {descriptors.length}
                        </Badge>
                      </div>
                      <div className="flex items-center justify-between">
                        <span className="text-sm text-gray-600">CÃ¢mera:</span>
                        <Badge
                          variant={cameraActive ? "default" : "secondary"}
                          className="text-xs"
                        >
                          {cameraActive ? "Conectada" : "Desconectada"}
                        </Badge>
                      </div>
                      <div className="flex items-center justify-between">
                        <span className="text-sm text-gray-600">
                          Threshold:
                        </span>
                        <Badge
                          variant="default"
                          className="text-xs bg-purple-500"
                        >
                          {recognitionThreshold.toFixed(2)} (ESTÃDIO - ALTA
                          PRECISÃƒO)
                        </Badge>
                      </div>

                      <div className="flex items-center justify-between">
                        <span className="text-sm text-gray-600">Status:</span>
                        <Badge
                          variant={personDetected ? "default" : "secondary"}
                          className="text-xs"
                        >
                          {personDetected ? "Detectando" : "Aguardando"}
                        </Badge>
                      </div>

                      {cameraError && (
                        <div className="text-xs text-red-600 bg-red-50 p-2 rounded">
                          Erro: {cameraError}
                        </div>
                      )}
                    </div>
                  </CardContent>
                </Card>

                {/* Instructions */}
                <Card className="bg-gradient-to-br from-green-50 to-blue-50 border-green-200">
                  <CardHeader>
                    <CardTitle className="text-green-800 flex items-center gap-2">
                      <AlertCircle className="h-5 w-5" />
                      InstruÃ§Ãµes de Uso
                    </CardTitle>
                  </CardHeader>
                  <CardContent>
                    <ul className="text-sm text-green-700 space-y-3">
                      <li className="flex items-start gap-3">
                        <div className="w-2 h-2 bg-green-500 rounded-full mt-2 flex-shrink-0"></div>
                        <span>Posicione-se bem na frente da cÃ¢mera</span>
                      </li>
                      <li className="flex items-start gap-3">
                        <div className="w-2 h-2 bg-green-500 rounded-full mt-2 flex-shrink-0"></div>
                        <span>
                          Certifique-se de que seu rosto estÃ¡ bem iluminado
                        </span>
                      </li>
                      <li className="flex items-start gap-3">
                        <div className="w-2 h-2 bg-green-500 rounded-full mt-2 flex-shrink-0"></div>
                        <span>
                          O reconhecimento acontece automaticamente a cada
                          segundo
                        </span>
                      </li>
                      <li className="flex items-start gap-3">
                        <div className="w-2 h-2 bg-green-500 rounded-full mt-2 flex-shrink-0"></div>
                        <span>
                          Apenas pessoas com ingressos vÃ¡lidos terÃ£o acesso
                          liberado
                        </span>
                      </li>
                      <li className="flex items-start gap-3">
                        <div className="w-2 h-2 bg-red-500 rounded-full mt-2 flex-shrink-0"></div>
                        <span className="font-semibold">
                          IMPORTANTE: Apenas uma pessoa por vez na frente da
                          cÃ¢mera
                        </span>
                      </li>
                    </ul>
                  </CardContent>
                </Card>

                {/* Features */}
                <Card className="bg-gradient-to-br from-purple-50 to-pink-50 border-purple-200">
                  <CardHeader>
                    <CardTitle className="text-purple-800 flex items-center gap-2">
                      <Zap className="h-5 w-5" />
                      Recursos do Sistema
                    </CardTitle>
                  </CardHeader>
                  <CardContent>
                    <div className="grid grid-cols-2 gap-3 text-xs">
                      <div className="bg-white/50 rounded-lg p-3 text-center">
                        <div className="font-semibold text-purple-700">
                          Reconhecimento
                        </div>
                        <div className="text-purple-600">Facial AvanÃ§ado</div>
                      </div>
                      <div className="bg-white/50 rounded-lg p-3 text-center">
                        <div className="font-semibold text-purple-700">
                          SeguranÃ§a
                        </div>
                        <div className="text-purple-600">Alta PrecisÃ£o</div>
                      </div>
                      <div className="bg-white/50 rounded-lg p-3 text-center">
                        <div className="font-semibold text-purple-700">
                          Velocidade
                        </div>
                        <div className="text-purple-600">
                          Processamento RÃ¡pido
                        </div>
                      </div>
                      <div className="bg-white/50 rounded-lg p-3 text-center">
                        <div className="font-semibold text-purple-700">
                          Interface
                        </div>
                        <div className="text-purple-600">Intuitiva</div>
                      </div>
                    </div>
                  </CardContent>
                </Card>
              </div>
            </div>
          </CardContent>
        </Card>
      </div>

      {/* Dialog de resultado */}
      <Dialog open={popup.open} onOpenChange={closePopup}>
        <DialogContent className="sm:max-w-md">
          <DialogHeader>
            <DialogTitle className="flex items-center gap-2">
              {popup.type === "success" ? (
                <CheckCircle className="h-6 w-6 text-green-500" />
              ) : popup.type === "error" ? (
                <XCircle className="h-6 w-6 text-red-500" />
              ) : (
                <AlertCircle className="h-6 w-6 text-yellow-500" />
              )}
              {popup.type === "success"
                ? "Acesso Liberado"
                : popup.type === "error"
                ? "Acesso Negado"
                : "Aviso"}
            </DialogTitle>
            <DialogDescription className="text-base font-medium">
              {popup.msg}
            </DialogDescription>
          </DialogHeader>
          <div className="flex justify-end">
            <Button onClick={closePopup} variant="outline">
              Fechar
            </Button>
          </div>
        </DialogContent>
      </Dialog>
    </div>
  );
};

export default FaceRecognition;
